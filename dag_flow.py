# Importando as bibliotecas do Airflow
from airflow import DAG
from datetime import datetime, timedelta
from airflow.decorators import task
from airflow.operators.python import ExternalPythonOperator, PythonVirtualenvOperator
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator
# Importando bibliotecas para o workflow
import sys
import requests
import json
import subprocess

global domain, target, auth, headers

domain = 'businesscorp.com.br'
target = 'businesscorp'
headers = {'Accept' : 'application/json', 'Content-Type' : 'application/json'}
auth=('usuario','senha') 

def consulta_subs(target, auth, headers):
    dic_consulta = {}
    data = {'size': 10000, "query": {"exists": {"field": "server.domain"}}}
    url = f'https://airflowserver:9200/{target}-*/_search'
    get_doc = requests.get(url, headers=headers, auth=auth, data=json.dumps(data), verify=False)
    parse_scan = json.loads(get_doc.text)
    for x in parse_scan['hits']['hits']:
        if(str(x['_source']['server.domain']) not in dic_consulta):
            dic_consulta[str(x['_source']['server.domain'])] = x['_source']['server.ip']
    return dic_consulta

def consulta_ip(target, auth, headers):
    list_consulta = []
    data = {'size': 10000, "query": {"exists": {"field": "server.ip"}}}
    url = f'https://airflowserver:9200/{target}-*/_search'
    get_doc = requests.get(url, headers=headers, auth=auth, data=json.dumps(data), verify=False)
    parse_scan = json.loads(get_doc.text)
    for x in parse_scan['hits']['hits']:
        if(x['_source']['server.ip'] not in list_consulta):
            list_consulta.append(x['_source']['server.ip'])
    print(list_consulta)
    return list_consulta



@task(task_id="inicio")
def inicio():
    print('inicio')

@task(task_id='fim', trigger_rule="all_done")
def fim():
    print('fim')

@task(task_id="assetfinder", trigger_rule="all_done")
def assetfinder():
    subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_assetfinder_airflow.py {target} {domain}', shell=True)

@task(task_id="httpx", trigger_rule="all_done")
def httpx(target):
    dic_subs = consulta_subs(target, auth, headers)
    for sub in dic_subs:
        subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_httpx_airflow.py {target} {sub} {dic_subs[sub]}', shell=True)

@task(task_id="nmap", trigger_rule="all_done")
def nmap(target):
    list_ip = consulta_subs(target, auth, headers)
    for ip in list_ip:
        subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_nmap_airflow.py {target} {ip}', shell=True)



default_args = {'owner': 'teste','depends_on_past':False,'start_date':datetime(2024,1,1),'retries':0 }

#Para o agendamento usar o parametro schedule_interval=timedelta(minutes=60)
with DAG('dag-flow', catchup=False, default_args=default_args) as dag:
    t0 = inicio()
    t1 = assetfinder(target)
    t2 = httpx(target)
    t3 = nmap(target)
    t4 = fim()

t0 >> t1 >>  [t2, t3] >> t4
