# Importando as bibliotecas do Airflow
from airflow import DAG
from datetime import datetime, timedelta
from airflow.decorators import task
from airflow.operators.python import ExternalPythonOperator, PythonVirtualenvOperator
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator
# Importando bibliotecas para o workflow
import sys
import requests
import json
import subprocess

global target, auth, headers

domain = 'businesscorp.com.br'
target = 'businesscorp'
headers = {'Accept' : 'application/json', 'Content-Type' : 'application/json'}
auth=('usuario','senha') 

@task(task_id="retorna_lista_domain", trigger_rule="all_done")
def retorna_lista_domain():
    return ['businesscorp.com.br', 'rh.businesscorp.com.br']

@task(task_id="retorna_dic_subs", trigger_rule="all_done")
def consulta_subs():
    dic_consulta = {}
    data = {'size': 10000, "query": {"exists": {"field": "server.domain"}}}
    url = f'https://airflowserver:9200/{target}-*/_search'
    get_doc = requests.get(url, headers=headers, auth=auth, data=json.dumps(data), verify=False)
    parse_scan = json.loads(get_doc.text)
    for x in parse_scan['hits']['hits']:
        if(str(x['_source']['server.domain']) not in dic_consulta):
            dic_consulta[str(x['_source']['server.domain'])] = x['_source']['server.ip']
    return dic_consulta

@task(task_id="retorna_list_ips", trigger_rule="all_done")
def consulta_ips():
    list_consulta = []
    data = {'size': 10000, "query": {"exists": {"field": "server.ip"}}}
    url = f'https://airflowserver:9200/{target}-*/_search'
    get_doc = requests.get(url, headers=headers, auth=auth, data=json.dumps(data), verify=False)
    parse_scan = json.loads(get_doc.text)
    for x in parse_scan['hits']['hits']:
        if(x['_source']['server.ip'] not in list_consulta):
            list_consulta.append(x['_source']['server.ip'])
    return list_consulta



@task(task_id="inicio")
def inicio():
    print('inicio')

@task(task_id='fim', trigger_rule="all_done")
def fim():
    print('fim')

@task(task_id="assetfinder", trigger_rule="all_done")
def assetfinder(domain):
    subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_assetfinder_airflow.py {target} {domain}', shell=True)

@task(task_id="httpx", trigger_rule="all_done")
def httpx(sub):
    subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_httpx_airflow.py {target} {sub[0]} {sub[1]}', shell=True)

@task(task_id="nmap", trigger_rule="all_done")
def nmap(ip):
    subprocess.check_output(f'python3 /docker/scripts/Modulo5_parse_nmap_airflow.py {target} {ip}', shell=True)

default_args = {'owner': 'teste','depends_on_past':False,'start_date':datetime(2024,1,1),'retries':0 }

#Para o agendamento usar o parametro schedule_interval=timedelta(minutes=60)
with DAG('dag-flow-dtm', catchup=False, default_args=default_args) as dag:
    t0 = inicio()
    t1 = assetfinder.expand(domain = retorna_lista_domain())
    t2 = httpx.expand(sub = consulta_subs())
    t3 = nmap.expand(ip = consulta_ips())
    t4 = fim()

t0 >> t1 >>  [t2, t3] >> t4
